{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 3: A First Model\n",
    "\n",
    "After getting a basic understanding of the data in the previous tutorial, we are ready to build a first AI model.\n",
    "In this notebook, we build and evaluate a simple model for identifying worm sections in nodule images.\n",
    "\n",
    "By the end of this notebook you will have created a first submission that you can submit to put your team on the leaderboard!\n",
    "\n",
    "**NOTE: This notebook will only work with a GPU instance. Make sure that you selected *ml.g4dn.xlarge* as instance type**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Picking the right approach\n",
    "\n",
    "The first challenge we have to address is how to even tackle the problem. What could be a good approach / algorithm? How are other people doing it?\n",
    "[PapersWithCode](https://paperswithcode.com/sota) is an amazing resource for exactly these questions. It lists typical problem classes together with the current state-of-the-art and links to popular frameworks.\n",
    "For our problem, [Object Detection](https://paperswithcode.com/task/object-detection) is the right category. If you follow the link you'll find a list of popular frameworks.\n",
    "\n",
    "[MMDetection](https://github.com/open-mmlab/mmdetection) is one of the most widely used and the one we picked for this tutorial. Not only does it provide a great [tutorial](https://github.com/open-mmlab/mmdetection/blob/master/demo/MMDet_Tutorial.ipynb), but also offers a variety of [different architectures and settings](https://github.com/open-mmlab/mmdetection#overview-of-benchmark-and-model-zoo) that you can play around with.\n",
    "\n",
    "In this notebook, we will adapt the MMdetection [tutorial](https://github.com/open-mmlab/mmdetection/blob/master/demo/MMDet_Tutorial.ipynb) to our problem and run it on a toy dataset.\n",
    "\n",
    "For those familiar with deep learning architectures, MMDetection can handle data loading, preperation, model building, and training by altering a few common settings in the configuration file. Data preperation also includes various data augmentation techinques like rotation or flipping. The majority of the most common CV arcitectures are already build and available via configuration.\n",
    "\n",
    "### *Further reading:*\n",
    "Going into details of object detection is beyond the scope of this tutorial. If you'd like to know more, here are two recommendations to get started:\n",
    "- [An introduction to R-CNNs and object detection in general](https://towardsdatascience.com/deep-dive-into-the-computer-vision-world-part-2-7a24efdb1a14)\n",
    "- [An graphic explanation how convolutional neural networks work](https://towardsdatascience.com/gentle-dive-into-math-behind-convolutional-neural-networks-79a07dd44cf9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "As in the other notebooks, we start by importing the relevant libraries and global settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "/mmcv/mmcv/_ext.cpython-36m-x86_64-linux-gnu.so: undefined symbol: _ZN2at5sliceERKNS_6TensorElN3c108optionalIlEES5_l",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-9b191282639f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatches\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRectangle\u001b[0m  \u001b[0;31m# Allows drawing the bounding boxes of the worm sections\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmmcv\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConfig\u001b[0m  \u001b[0;31m# Loading and accessing MMDetection configuration files\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmmdet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapis\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minference_detector\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_detector\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_detector\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_random_seed\u001b[0m  \u001b[0;31m# Part of the MMDetection framework\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmmdet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbuild_dataset\u001b[0m  \u001b[0;31m# Part of the MMDetection framework\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmmdet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbuild_detector\u001b[0m  \u001b[0;31m# Part of the MMDetection framework\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mmdetection/mmdet/apis/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Copyright (c) OpenMMLab. All rights reserved.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m from .inference import (async_inference_detector, inference_detector,\n\u001b[0m\u001b[1;32m      3\u001b[0m                         init_detector, show_result_pyplot)\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmulti_gpu_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msingle_gpu_test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m from .train import (get_root_logger, init_random_seed, set_random_seed,\n",
      "\u001b[0;32m/mmdetection/mmdet/apis/inference.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmmcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRoIPool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmmcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcollate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscatter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmmcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunner\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_checkpoint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mmcv/mmcv/ops/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Copyright (c) OpenMMLab. All rights reserved.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mactive_rotated_filter\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mactive_rotated_filter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0massign_score_withk\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0massign_score_withk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mball_query\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mball_query\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbbox\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbbox_overlaps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mmcv/mmcv/ops/active_rotated_filter.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m ext_module = ext_loader.load_ext(\n\u001b[1;32m      9\u001b[0m     \u001b[0;34m'_ext'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     ['active_rotated_filter_forward', 'active_rotated_filter_backward'])\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mmcv/mmcv/utils/ext_loader.py\u001b[0m in \u001b[0;36mload_ext\u001b[0;34m(name, funcs)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mload_ext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfuncs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mmcv.'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mfun\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfuncs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf'{fun} miss in module {name}'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    124\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: /mmcv/mmcv/_ext.cpython-36m-x86_64-linux-gnu.so: undefined symbol: _ZN2at5sliceERKNS_6TensorElN3c108optionalIlEES5_l"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt  # Used for plotting\n",
    "import mmcv  # Object detection framework\n",
    "import os  # Interaction with the file system\n",
    "import pandas as pd  # Home of the DataFrame construct, _the_ most important object for Data Science\n",
    "import sys  # Python system library needed to load custom functions\n",
    "\n",
    "from matplotlib.patches import Rectangle  # Allows drawing the bounding boxes of the worm sections\n",
    "from mmcv import Config  # Loading and accessing MMDetection configuration files\n",
    "from mmdet.apis import inference_detector, init_detector, train_detector, set_random_seed  # Part of the MMDetection framework\n",
    "from mmdet.datasets import build_dataset  # Part of the MMDetection framework\n",
    "from mmdet.models import build_detector  # Part of the MMDetection framework\n",
    "\n",
    "from PIL import Image  # For loading image files\n",
    "from tqdm import tqdm  # for timing a for loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../src')  # Add the source directory to the PYTHONPATH. This allows to import local functions and modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Dataset import OnchoDataset\n",
    "from detection_util import create_predictions\n",
    "from gdsc_score import get_leaderboard_score\n",
    "from gdsc_util import download_directory, download_file, load_sections_df, set_up_logging, PROJECT_DIR\n",
    "from PredictionEvaluator import PredictionEvaluator\n",
    "\n",
    "set_up_logging()  # Sets up logging to console and the .log file\n",
    "data_folder = str(PROJECT_DIR / 'data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/root/data/gdsc5-tutorials-public/data'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PROJECT_DIR\n",
    "data_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OnchoDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing the Training Dataset\n",
    "\n",
    "Whenever you start working with a new framework you can expect issues with the setup.\n",
    "To ensure that we can quickly try things out we create a small subset of our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65687"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "section_df = load_sections_df(f'{data_folder}/gdsc_train.csv')\n",
    "len(section_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparing training and testing data \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our complete dataset has more than 65.000 rows. Let's create two small dummy sets with 100 and 50 entries only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:: class imbalance handling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'section_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-0925ba3b7b38>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdummy_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msection_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdummy_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msection_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3000\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3500\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdummy_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{data_folder}/dummy_train.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m';'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdummy_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{data_folder}/dummy_test.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m';'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'section_df' is not defined"
     ]
    }
   ],
   "source": [
    "dummy_train = section_df[1000:3000]\n",
    "dummy_test = section_df[3000:3500]\n",
    "dummy_train.to_csv(f'{data_folder}/dummy_train.csv', sep=';')\n",
    "dummy_test.to_csv(f'{data_folder}/dummy_test.csv', sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We store the reduced sets under *../data*. Verify that you can find and open the files there. \n",
    "To make sure that everything works, let's load the files again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>study</th>\n",
       "      <th>staining</th>\n",
       "      <th>xmin</th>\n",
       "      <th>xmax</th>\n",
       "      <th>ymin</th>\n",
       "      <th>ymax</th>\n",
       "      <th>height</th>\n",
       "      <th>width</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>section_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>105_A@4829-3641-5098-3824</th>\n",
       "      <td>105_A.jpg</td>\n",
       "      <td>Study_2</td>\n",
       "      <td>A</td>\n",
       "      <td>4829</td>\n",
       "      <td>5098</td>\n",
       "      <td>3641</td>\n",
       "      <td>3824</td>\n",
       "      <td>7137</td>\n",
       "      <td>8192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105_A@4888-2629-5122-2930</th>\n",
       "      <td>105_A.jpg</td>\n",
       "      <td>Study_2</td>\n",
       "      <td>A</td>\n",
       "      <td>4888</td>\n",
       "      <td>5122</td>\n",
       "      <td>2629</td>\n",
       "      <td>2930</td>\n",
       "      <td>7137</td>\n",
       "      <td>8192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105_A@4935-2054-5165-2250</th>\n",
       "      <td>105_A.jpg</td>\n",
       "      <td>Study_2</td>\n",
       "      <td>A</td>\n",
       "      <td>4935</td>\n",
       "      <td>5165</td>\n",
       "      <td>2054</td>\n",
       "      <td>2250</td>\n",
       "      <td>7137</td>\n",
       "      <td>8192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105_A@5003-1858-5295-2193</th>\n",
       "      <td>105_A.jpg</td>\n",
       "      <td>Study_2</td>\n",
       "      <td>A</td>\n",
       "      <td>5003</td>\n",
       "      <td>5295</td>\n",
       "      <td>1858</td>\n",
       "      <td>2193</td>\n",
       "      <td>7137</td>\n",
       "      <td>8192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105_A@5056-1716-5411-2057</th>\n",
       "      <td>105_A.jpg</td>\n",
       "      <td>Study_2</td>\n",
       "      <td>A</td>\n",
       "      <td>5056</td>\n",
       "      <td>5411</td>\n",
       "      <td>1716</td>\n",
       "      <td>2057</td>\n",
       "      <td>7137</td>\n",
       "      <td>8192</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           file_name    study staining  xmin  xmax  ymin  \\\n",
       "section_id                                                                 \n",
       "105_A@4829-3641-5098-3824  105_A.jpg  Study_2        A  4829  5098  3641   \n",
       "105_A@4888-2629-5122-2930  105_A.jpg  Study_2        A  4888  5122  2629   \n",
       "105_A@4935-2054-5165-2250  105_A.jpg  Study_2        A  4935  5165  2054   \n",
       "105_A@5003-1858-5295-2193  105_A.jpg  Study_2        A  5003  5295  1858   \n",
       "105_A@5056-1716-5411-2057  105_A.jpg  Study_2        A  5056  5411  1716   \n",
       "\n",
       "                           ymax  height  width  \n",
       "section_id                                      \n",
       "105_A@4829-3641-5098-3824  3824    7137   8192  \n",
       "105_A@4888-2629-5122-2930  2930    7137   8192  \n",
       "105_A@4935-2054-5165-2250  2250    7137   8192  \n",
       "105_A@5003-1858-5295-2193  2193    7137   8192  \n",
       "105_A@5056-1716-5411-2057  2057    7137   8192  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_train = load_sections_df(f'{data_folder}/dummy_train.csv')\n",
    "dummy_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_train.file_name.nunique()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks good! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a MMDetection Configuration File\n",
    "\n",
    "MMDetection relies on extensive configuration files. The usual process is to adapt an already existing configuration file and apply transfer learning.\n",
    "To do this, we first need to download the configuration and weights files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-06-20 17:13:18--  https://download.openmmlab.com/mmdetection/v2.0/vfnet/vfnet_r50_fpn_1x_coco/vfnet_r50_fpn_1x_coco_20201027-38db6f58.pth\n",
      "Resolving download.openmmlab.com (download.openmmlab.com)... 47.252.96.28\n",
      "Connecting to download.openmmlab.com (download.openmmlab.com)|47.252.96.28|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "\n",
      "    The file is already fully retrieved; nothing to do.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Make a new folder in the data folder\n",
    "# !mkdir ../data/checkpoints\n",
    "# !mkdir ../data/checkpoints1\n",
    "# !mkdir ../data/checkpoints/vfnet\n",
    "\n",
    "# Install wget, a program for downloading files from the internet\n",
    "# !apt update\n",
    "# !apt install wget\n",
    "\n",
    "\n",
    "#Vfnet config and weights file \n",
    "# vfnet with resnet 50 back bone \n",
    "!wget -c https://download.openmmlab.com/mmdetection/v2.0/vfnet/vfnet_r50_fpn_1x_coco/vfnet_r50_fpn_1x_coco_20201027-38db6f58.pth -O ../data/checkpoints/vfnet/vfnet_r50_fpn_1x_coco_20201027-38db6f58.pth\n",
    "\n",
    "# vfnet with resenet 50 back bone \n",
    "# !wget -c https://download.openmmlab.com/mmdetection/v2.0/vfnet/vfnet_r50_fpn_mdconv_c3-c5_mstrain_2x_coco/vfnet_r50_fpn_mdconv_c3-c5_mstrain_2x_coco_20201027pth-6879c318.pth -o ../data/checkpoints/vfnet/vfnet_r50_fpn_mdconv_c3-c5_mstrain_2x_coco_20201027pth-6879c318.pth\n",
    "\n",
    "# vfnet with r101 back bone \n",
    "# !wget -c https://download.openmmlab.com/mmdetection/v2.0/vfnet/vfnet_r101_fpn_1x_coco/vfnet_r101_fpn_1x_coco_20201027pth-c831ece7.pth -O ../data/checkpoints/vfnet/vfnet_r101_fpn_1x_coco_20201027pth-c831ece7.pth\n",
    "    \n",
    "    \n",
    "# Download the config and weights file\n",
    "# !wget -c https://download.openmmlab.com/mmdetection/v2.0/mask_rcnn/mask_rcnn_r50_caffe_fpn_mstrain-poly_3x_coco/mask_rcnn_r50_caffe_fpn_mstrain-poly_3x_coco_bbox_mAP-0.408__segm_mAP-0.37_20200504_163245-42aa3d00.pth -O ../data/checkpoints/mask_rcnn_r50_caffe_fpn_mstrain-poly_3x_coco_bbox_mAP-0.408__segm_mAP-0.37_20200504_163245-42aa3d00.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmdet.apis import set_random_seed\n",
    "from mmdet.apis import train_detector, init_detector\n",
    "import torch "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The configuration file is part of the mmdetection package that is already installed on this image. Hence we can load our test configuration via"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tutorial 3 \n",
    "# faster RCNN\n",
    "\n",
    "# cfg = Config.fromfile('/mmdetection/configs/faster_rcnn/faster_rcnn_r50_caffe_fpn_mstrain_1x_coco.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom configuration for vfnet \n",
    "# cfg = Config.fromfile(\"/mmdetection/configs/vfnet/vfnet_r50_fpn_mstrain_2x_coco.py\")\n",
    "# cfg = Config.fromfile(\"/mmdetection/configs/vfnet/vfnet_r50_fpn_mdconv_c3-c5_mstrain_2x_coco.py\")\n",
    "\n",
    "# vfnet with r101 back bone \n",
    "# cfg = Config.fromfile(\"/mmdetection/configs/vfnet/vfnet_r101_fpn_1x_coco.py\")\n",
    "# ran with only 3 epochs\n",
    "\n",
    "#vfnet with r50 back bone \n",
    "# submission(1-4)\n",
    "cfg = Config.fromfile(\"/mmdetection/configs/vfnet/vfnet_r50_fpn_1x_coco.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The configuration is a dictionary-like object that stores our configuration settings. Is has [a lot](https://mmdetection.readthedocs.io/en/latest/tutorials/config.html) of settings and with the right options, you can run the [really advanced models](https://github.com/open-mmlab/mmdetection/blob/master/docs/en/model_zoo.md).\n",
    "Below we modify some of those settings to point the model to our train and test data.\n",
    "\n",
    "We start by defining the structure and location of our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify dataset type and path\n",
    "cfg.dataset_type = 'OnchoDataset' #this is a custom data loader script we created for the GDSC you can view it in src/Dataset.py\n",
    "cfg.data_root = data_folder\n",
    "\n",
    "cfg.data.train.type = 'OnchoDataset'\n",
    "cfg.data.train.data_root = data_folder      # path to the folder data\n",
    "cfg.data.train.img_prefix = 'jpgs/'         # path from data_root to the images folder\n",
    "cfg.data.train.ann_file = 'dummy_train.csv' # the file containing the train data labels\n",
    "\n",
    "cfg.data.test.type = 'OnchoDataset'\n",
    "cfg.data.test.data_root = data_folder\n",
    "cfg.data.test.img_prefix = 'jpgs/'\n",
    "cfg.data.test.ann_file = 'dummy_test.csv'\n",
    "\n",
    "cfg.data.val.type = 'OnchoDataset'          # We will not use a separate validation data set in this tutorial, but we need to specify the values to overwrite the COCO defaults.\n",
    "cfg.data.val.data_root = data_folder\n",
    "cfg.data.val.img_prefix = 'jpgs/'\n",
    "cfg.data.val.ann_file = 'dummy_test.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We specify where to save the results and where the weights we will use were downloaded to. We also set the number of workers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can still use the pre-trained Mask RCNN model though we do not need to use the mask branch\n",
    "# cfg.load_from = f'{data_folder}/checkpoints/mask_rcnn_r50_caffe_fpn_mstrain-poly_3x_coco_bbox_mAP-0.408__segm_mAP-0.37_20200504_163245-42aa3d00.pth'\n",
    "\n",
    "#vfnet model \n",
    "# cfg.load_from = f'{data_folder}/checkpoints1/vfnet_r50_fpn_mdconv_c3-c5_mstrain_2x_coco/vfnet_r50_fpn_mdconv_c3-c5_mstrain_2x_coco_20201027pth-6879c318.pth'\n",
    "# cfg.load_from = f'{data_folder}/checkpoints/vfnet_r50_fpn_mdconv_c3-c5_mstrain_2x_coco_20201027pth-6879c318.pth'\n",
    "# cfg.load_from = f'{data_folder}/checkpoints/vfnet/vfnet_r50_fpn_mdconv_c3-c5_mstrain_2x_coco_20201027pth-6879c318.pth'\n",
    "\n",
    "\n",
    "# vfnet with r101 back bone \n",
    "# cfg.load_from = f'{data_folder}/checkpoints/vfnet/vfnet_r101_fpn_1x_coco_20201027pth-c831ece7.pth'\n",
    "\n",
    "\n",
    "# vfnet with r50 back bone \n",
    "cfg.load_from = f'{data_folder}/checkpoints/vfnet/vfnet_r50_fpn_1x_coco_20201027-38db6f58.pth'\n",
    "\n",
    "\n",
    "\n",
    "# Set up working dir to save files and logs.\n",
    "cfg.work_dir = f'{data_folder}/vfnet_r50_exp5/'\n",
    "# Ensure work_dir exists\n",
    "mmcv.mkdir_or_exist(os.path.abspath(cfg.work_dir))\n",
    "\n",
    "# Set seed thus the results are more reproducible\n",
    "cfg.seed = 0\n",
    "set_random_seed(0, deterministic=False)\n",
    "cfg.gpu_ids = range(1)  # not available in vfnet config\n",
    "\n",
    "# cfg.data.samples_per_gpu = 3 # These numbers will change depending on the size of your model and GPU.\n",
    "# cfg.data.samples_per_gpu = 1 # submission 1\n",
    "cfg.data.samples_per_gpu = 2 #  \n",
    "\n",
    "# cfg.data.workers_per_gpu = 1 # These values are what we have found to be best for this model and GPU\n",
    "cfg.data.workers_per_gpu = 0 # These values are what we have found to be best for this model and GPU\n",
    "\n",
    "cfg.device = 'cuda' # This defines that we will use a GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next are the model settings. One thing we have to change is the number of classes to predict. Since we only have one class (worm section), we need to set this to one.\n",
    "We also change the learning rate since we only have one GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modify number of classes of the model in box head\n",
    "# cfg.model.roi_head.bbox_head.num_classes = 1  # a worm section is the only object we are detecting\n",
    "\n",
    "\n",
    "#vfnet\n",
    "cfg.model.bbox_head.num_classes = 1\n",
    "cfg.classes = (\"worm_section\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# The original learning rate (LR) is set for 8-GPU training.\n",
    "# We divide it by 8 since we only use one GPU and multiply by the number of GPU workers.\n",
    "# cfg.optimizer.lr = 0.02 / 8 * cfg.data.workers_per_gpu\n",
    "cfg.lr_config.warmup = None\n",
    "cfg.log_config.interval = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we specify how and when to evaluate the model and how long to train the model. We will use the [mAP](https://blog.paperspace.com/mean-average-precision/#:~:text=To%20evaluate%20object%20detection%20models,model%20is%20in%20its%20detections.) metric to evaluate how the training is going.\n",
    "\n",
    "For our test run, we will only train for three epochs. For a real training run you'll want to set this number higher.\n",
    "After each epoch, the current weights will be saved in the *work_dir* folder we set above. Also the model will be evaluated on the test data set.\n",
    "This allows us to check if we should continue training or stop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the evaluation metric since we use customized dataset.\n",
    "cfg.evaluation.metric = 'mAP'\n",
    "# We can set the evaluation interval to reduce the evaluation times\n",
    "cfg.evaluation.interval = 1\n",
    "# We can set the checkpoint saving interval to reduce the storage cost\n",
    "cfg.checkpoint_config.interval = 3\n",
    "# How long do we want to train\n",
    "cfg.runner.max_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cfg.auto_scale_lr.base_batch_size = 16 # submission 1 (3 epochs)\n",
    "# cfg.auto_scale_lr.base_batch_size = 8 # submission 2\n",
    "# cfg.auto_scale_lr.base_batch_size = 8 # submission 3\n",
    "# cfg.auto_scale_lr.base_batch_size = 8 # submission 4\n",
    "# cfg.auto_scale_lr.base_batch_size = 16 # submission 5 \n",
    "\n",
    "cfg.auto_scale_lr.base_batch_size = 32 # submission 6 \n",
    "\n",
    "\n",
    "# cfg.optimizer.lr = 0.02/8*2 #submission 1 > (3 epochs)\n",
    "# cfg.optimizer.lr = 0.02/8 #submission 2   > 2.5 learning rate \n",
    "# cfg.optimizer.lr = 0.02/8*0 #submission 3 > 0 learning rate \n",
    "# cfg.optimizer.lr = 0.001 #submission 4    > 1.000e-03 learning rate \n",
    "cfg.optimizer.lr = 0.002  # submission 5 , 6  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0025"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.02/8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Config (path: /mmdetection/configs/vfnet/vfnet_r50_fpn_1x_coco.py): {'dataset_type': 'OnchoDataset', 'data_root': '/root/data/gdsc5-tutorials-public/data', 'img_norm_cfg': {'mean': [123.675, 116.28, 103.53], 'std': [58.395, 57.12, 57.375], 'to_rgb': True}, 'train_pipeline': [{'type': 'LoadImageFromFile'}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'img_scale': (1333, 800), 'keep_ratio': True}, {'type': 'RandomFlip', 'flip_ratio': 0.5}, {'type': 'Normalize', 'mean': [123.675, 116.28, 103.53], 'std': [58.395, 57.12, 57.375], 'to_rgb': True}, {'type': 'Pad', 'size_divisor': 32}, {'type': 'DefaultFormatBundle'}, {'type': 'Collect', 'keys': ['img', 'gt_bboxes', 'gt_labels']}], 'test_pipeline': [{'type': 'LoadImageFromFile'}, {'type': 'MultiScaleFlipAug', 'img_scale': (1333, 800), 'flip': False, 'transforms': [{'type': 'Resize', 'keep_ratio': True}, {'type': 'RandomFlip'}, {'type': 'Normalize', 'mean': [123.675, 116.28, 103.53], 'std': [58.395, 57.12, 57.375], 'to_rgb': True}, {'type': 'Pad', 'size_divisor': 32}, {'type': 'DefaultFormatBundle'}, {'type': 'Collect', 'keys': ['img']}]}], 'data': {'samples_per_gpu': 2, 'workers_per_gpu': 0, 'train': {'type': 'OnchoDataset', 'ann_file': 'dummy_train.csv', 'img_prefix': 'jpgs/', 'pipeline': [{'type': 'LoadImageFromFile'}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'img_scale': (1333, 800), 'keep_ratio': True}, {'type': 'RandomFlip', 'flip_ratio': 0.5}, {'type': 'Normalize', 'mean': [123.675, 116.28, 103.53], 'std': [58.395, 57.12, 57.375], 'to_rgb': True}, {'type': 'Pad', 'size_divisor': 32}, {'type': 'DefaultFormatBundle'}, {'type': 'Collect', 'keys': ['img', 'gt_bboxes', 'gt_labels']}], 'data_root': '/root/data/gdsc5-tutorials-public/data'}, 'val': {'type': 'OnchoDataset', 'ann_file': 'dummy_test.csv', 'img_prefix': 'jpgs/', 'pipeline': [{'type': 'LoadImageFromFile'}, {'type': 'MultiScaleFlipAug', 'img_scale': (1333, 800), 'flip': False, 'transforms': [{'type': 'Resize', 'keep_ratio': True}, {'type': 'RandomFlip'}, {'type': 'Normalize', 'mean': [123.675, 116.28, 103.53], 'std': [58.395, 57.12, 57.375], 'to_rgb': True}, {'type': 'Pad', 'size_divisor': 32}, {'type': 'DefaultFormatBundle'}, {'type': 'Collect', 'keys': ['img']}]}], 'data_root': '/root/data/gdsc5-tutorials-public/data'}, 'test': {'type': 'OnchoDataset', 'ann_file': 'dummy_test.csv', 'img_prefix': 'jpgs/', 'pipeline': [{'type': 'LoadImageFromFile'}, {'type': 'MultiScaleFlipAug', 'img_scale': (1333, 800), 'flip': False, 'transforms': [{'type': 'Resize', 'keep_ratio': True}, {'type': 'RandomFlip'}, {'type': 'Normalize', 'mean': [123.675, 116.28, 103.53], 'std': [58.395, 57.12, 57.375], 'to_rgb': True}, {'type': 'Pad', 'size_divisor': 32}, {'type': 'DefaultFormatBundle'}, {'type': 'Collect', 'keys': ['img']}]}], 'data_root': '/root/data/gdsc5-tutorials-public/data'}}, 'evaluation': {'interval': 1, 'metric': 'mAP'}, 'optimizer': {'type': 'SGD', 'lr': 0.002, 'momentum': 0.9, 'weight_decay': 0.0001, 'paramwise_cfg': {'bias_lr_mult': 2.0, 'bias_decay_mult': 0.0}}, 'optimizer_config': {'grad_clip': None}, 'lr_config': {'policy': 'step', 'warmup': None, 'warmup_iters': 500, 'warmup_ratio': 0.1, 'step': [8, 11]}, 'runner': {'type': 'EpochBasedRunner', 'max_epochs': 10}, 'checkpoint_config': {'interval': 3}, 'log_config': {'interval': 10, 'hooks': [{'type': 'TextLoggerHook'}]}, 'custom_hooks': [{'type': 'NumClassCheckHook'}], 'dist_params': {'backend': 'nccl'}, 'log_level': 'INFO', 'load_from': '/root/data/gdsc5-tutorials-public/data/checkpoints/vfnet/vfnet_r50_fpn_1x_coco_20201027-38db6f58.pth', 'resume_from': None, 'workflow': [('train', 1)], 'opencv_num_threads': 0, 'mp_start_method': 'fork', 'auto_scale_lr': {'enable': False, 'base_batch_size': 32}, 'model': {'type': 'VFNet', 'backbone': {'type': 'ResNet', 'depth': 50, 'num_stages': 4, 'out_indices': (0, 1, 2, 3), 'frozen_stages': 1, 'norm_cfg': {'type': 'BN', 'requires_grad': True}, 'norm_eval': True, 'style': 'pytorch', 'init_cfg': {'type': 'Pretrained', 'checkpoint': 'torchvision://resnet50'}}, 'neck': {'type': 'FPN', 'in_channels': [256, 512, 1024, 2048], 'out_channels': 256, 'start_level': 1, 'add_extra_convs': 'on_output', 'num_outs': 5, 'relu_before_extra_convs': True}, 'bbox_head': {'type': 'VFNetHead', 'num_classes': 1, 'in_channels': 256, 'stacked_convs': 3, 'feat_channels': 256, 'strides': [8, 16, 32, 64, 128], 'center_sampling': False, 'dcn_on_last_conv': False, 'use_atss': True, 'use_vfl': True, 'loss_cls': {'type': 'VarifocalLoss', 'use_sigmoid': True, 'alpha': 0.75, 'gamma': 2.0, 'iou_weighted': True, 'loss_weight': 1.0}, 'loss_bbox': {'type': 'GIoULoss', 'loss_weight': 1.5}, 'loss_bbox_refine': {'type': 'GIoULoss', 'loss_weight': 2.0}}, 'train_cfg': {'assigner': {'type': 'ATSSAssigner', 'topk': 9}, 'allowed_border': -1, 'pos_weight': -1, 'debug': False}, 'test_cfg': {'nms_pre': 1000, 'min_bbox_size': 0, 'score_thr': 0.05, 'nms': {'type': 'nms', 'iou_threshold': 0.6}, 'max_per_img': 100}}, 'work_dir': '/root/data/gdsc5-tutorials-public/data/vfnet_r50_exp5/', 'seed': 0, 'gpu_ids': range(0, 1), 'device': 'cuda', 'classes': 'worm_section'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training of the first Model\n",
    "\n",
    "We're now ready to train a first simple model! The first step is to prepare the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-20 20:46:23,594 - Dataset - INFO - Building Dataset\n",
      "2022-06-20 20:46:23,594 - Dataset - INFO - Building Dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mmdetection/mmdet/datasets/custom.py:180: UserWarning: CustomDataset does not support filtering empty gt images.\n",
      "  'CustomDataset does not support filtering empty gt images.')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[\n",
       " OnchoDataset Train dataset with number of images 28, and instance counts: \n",
       " +-------------+-------+----------+-------+----------+-------+----------+-------+----------+-------+\n",
       " | category    | count | category | count | category | count | category | count | category | count |\n",
       " +-------------+-------+----------+-------+----------+-------+----------+-------+----------+-------+\n",
       " |             |       |          |       |          |       |          |       |          |       |\n",
       " | 0 [section] | 2000  |          |       |          |       |          |       |          |       |\n",
       " +-------------+-------+----------+-------+----------+-------+----------+-------+----------+-------+]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets = [build_dataset(cfg.data.train)]\n",
    "\n",
    "datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset contains exactly 100 worm sections, one for each row on the *dummy_train* DataFrame. We also get a warning about filtering empty ground truth images which we can ignore since we don't have those.\n",
    "\n",
    "Next, we initialize the model according to the configuration. *train_cfg* determins on which data to train the model, *test_cfg* on which data to test the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['section']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets[0].CLASSES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_detector(cfg.model, train_cfg=cfg.get('train_cfg'), test_cfg=cfg.get('test_cfg'))\n",
    "model.CLASSES = datasets[0].CLASSES  # Add an attribute for visualization convenience\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function mmdet.apis.train.train_detector(model, dataset, cfg, distributed=False, validate=False, timestamp=None, meta=None)>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_detector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally, we can train the model. The log output helps us understand how well the model is doing. \n",
    "Since we set the *evaluation.interval* to *1*, the model will be evaluated after every epoch. In general you want to continue training as long as the *mAP* score increases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-20 20:46:34,321 - mmdet - INFO - Automatic scaling of learning rate (LR) has been disabled.\n",
      "2022-06-20 20:46:34,321 - mmdet - INFO - Automatic scaling of learning rate (LR) has been disabled.\n",
      "2022-06-20 20:46:34,345 - Dataset - INFO - Building Dataset\n",
      "2022-06-20 20:46:34,345 - Dataset - INFO - Building Dataset\n",
      "2022-06-20 20:46:34,379 - mmdet - INFO - load checkpoint from local path: /root/data/gdsc5-tutorials-public/data/checkpoints/vfnet/vfnet_r50_fpn_1x_coco_20201027-38db6f58.pth\n",
      "2022-06-20 20:46:34,379 - mmdet - INFO - load checkpoint from local path: /root/data/gdsc5-tutorials-public/data/checkpoints/vfnet/vfnet_r50_fpn_1x_coco_20201027-38db6f58.pth\n",
      "2022-06-20 20:46:34,528 - mmdet - WARNING - The model and loaded state dict do not match exactly\n",
      "\n",
      "size mismatch for bbox_head.vfnet_cls.weight: copying a param with shape torch.Size([80, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([1, 256, 3, 3]).\n",
      "size mismatch for bbox_head.vfnet_cls.bias: copying a param with shape torch.Size([80]) from checkpoint, the shape in current model is torch.Size([1]).\n",
      "2022-06-20 20:46:34,528 - mmdet - WARNING - The model and loaded state dict do not match exactly\n",
      "\n",
      "size mismatch for bbox_head.vfnet_cls.weight: copying a param with shape torch.Size([80, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([1, 256, 3, 3]).\n",
      "size mismatch for bbox_head.vfnet_cls.bias: copying a param with shape torch.Size([80]) from checkpoint, the shape in current model is torch.Size([1]).\n",
      "2022-06-20 20:46:34,534 - mmdet - INFO - Start running, host: root@gdsc5-smstudio-cust-ml-g4dn-xlarge-6b8714ee1695481ee0b95d699111, work_dir: /root/data/gdsc5-tutorials-public/data/vfnet_r50_exp5\n",
      "2022-06-20 20:46:34,534 - mmdet - INFO - Start running, host: root@gdsc5-smstudio-cust-ml-g4dn-xlarge-6b8714ee1695481ee0b95d699111, work_dir: /root/data/gdsc5-tutorials-public/data/vfnet_r50_exp5\n",
      "2022-06-20 20:46:34,536 - mmdet - INFO - Hooks will be executed in the following order:\n",
      "before_run:\n",
      "(VERY_HIGH   ) StepLrUpdaterHook                  \n",
      "(NORMAL      ) CheckpointHook                     \n",
      "(LOW         ) EvalHook                           \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_train_epoch:\n",
      "(VERY_HIGH   ) StepLrUpdaterHook                  \n",
      "(NORMAL      ) NumClassCheckHook                  \n",
      "(LOW         ) IterTimerHook                      \n",
      "(LOW         ) EvalHook                           \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_train_iter:\n",
      "(VERY_HIGH   ) StepLrUpdaterHook                  \n",
      "(LOW         ) IterTimerHook                      \n",
      "(LOW         ) EvalHook                           \n",
      " -------------------- \n",
      "after_train_iter:\n",
      "(ABOVE_NORMAL) OptimizerHook                      \n",
      "(NORMAL      ) CheckpointHook                     \n",
      "(LOW         ) IterTimerHook                      \n",
      "(LOW         ) EvalHook                           \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "after_train_epoch:\n",
      "(NORMAL      ) CheckpointHook                     \n",
      "(LOW         ) EvalHook                           \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_val_epoch:\n",
      "(NORMAL      ) NumClassCheckHook                  \n",
      "(LOW         ) IterTimerHook                      \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_val_iter:\n",
      "(LOW         ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_iter:\n",
      "(LOW         ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_epoch:\n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "after_run:\n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "2022-06-20 20:46:34,536 - mmdet - INFO - Hooks will be executed in the following order:\n",
      "before_run:\n",
      "(VERY_HIGH   ) StepLrUpdaterHook                  \n",
      "(NORMAL      ) CheckpointHook                     \n",
      "(LOW         ) EvalHook                           \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_train_epoch:\n",
      "(VERY_HIGH   ) StepLrUpdaterHook                  \n",
      "(NORMAL      ) NumClassCheckHook                  \n",
      "(LOW         ) IterTimerHook                      \n",
      "(LOW         ) EvalHook                           \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_train_iter:\n",
      "(VERY_HIGH   ) StepLrUpdaterHook                  \n",
      "(LOW         ) IterTimerHook                      \n",
      "(LOW         ) EvalHook                           \n",
      " -------------------- \n",
      "after_train_iter:\n",
      "(ABOVE_NORMAL) OptimizerHook                      \n",
      "(NORMAL      ) CheckpointHook                     \n",
      "(LOW         ) IterTimerHook                      \n",
      "(LOW         ) EvalHook                           \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "after_train_epoch:\n",
      "(NORMAL      ) CheckpointHook                     \n",
      "(LOW         ) EvalHook                           \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_val_epoch:\n",
      "(NORMAL      ) NumClassCheckHook                  \n",
      "(LOW         ) IterTimerHook                      \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_val_iter:\n",
      "(LOW         ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_iter:\n",
      "(LOW         ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_epoch:\n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "after_run:\n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "2022-06-20 20:46:34,537 - mmdet - INFO - workflow: [('train', 1)], max: 10 epochs\n",
      "2022-06-20 20:46:34,537 - mmdet - INFO - workflow: [('train', 1)], max: 10 epochs\n",
      "2022-06-20 20:46:34,538 - mmdet - INFO - Checkpoints will be saved to /root/data/gdsc5-tutorials-public/data/vfnet_r50_exp5 by HardDiskBackend.\n",
      "2022-06-20 20:46:34,538 - mmdet - INFO - Checkpoints will be saved to /root/data/gdsc5-tutorials-public/data/vfnet_r50_exp5 by HardDiskBackend.\n",
      "[2022-06-20 20:46:36.759 gdsc5-smstudio-cust-ml-g4dn-xlarge-6b8714ee1695481ee0b95d699111:2188 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\n",
      "[2022-06-20 20:46:36.793 gdsc5-smstudio-cust-ml-g4dn-xlarge-6b8714ee1695481ee0b95d699111:2188 INFO profiler_config_parser.py:102] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\n",
      "2022-06-20 20:47:06,292 - mmdet - INFO - Epoch [1][10/15]\tlr: 2.000e-03, eta: 0:07:23, time: 3.164, data_time: 2.340, memory: 3370, loss_cls: 1.2028, loss_bbox: 0.6483, loss_bbox_rf: 0.8705, loss: 2.7217\n",
      "2022-06-20 20:47:06,292 - mmdet - INFO - Epoch [1][10/15]\tlr: 2.000e-03, eta: 0:07:23, time: 3.164, data_time: 2.340, memory: 3370, loss_cls: 1.2028, loss_bbox: 0.6483, loss_bbox_rf: 0.8705, loss: 2.7217\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 13/13, 0.8 task/s, elapsed: 17s, ETA:     0s\n",
      "---------------iou_thr: 0.5---------------\n",
      "2022-06-20 20:47:36,603 - mmdet - INFO - \n",
      "+---------+-----+------+--------+-------+\n",
      "| class   | gts | dets | recall | ap    |\n",
      "+---------+-----+------+--------+-------+\n",
      "| section | 500 | 1300 | 0.450  | 0.151 |\n",
      "+---------+-----+------+--------+-------+\n",
      "| mAP     |     |      |        | 0.151 |\n",
      "+---------+-----+------+--------+-------+\n",
      "2022-06-20 20:47:36,603 - mmdet - INFO - \n",
      "+---------+-----+------+--------+-------+\n",
      "| class   | gts | dets | recall | ap    |\n",
      "+---------+-----+------+--------+-------+\n",
      "| section | 500 | 1300 | 0.450  | 0.151 |\n",
      "+---------+-----+------+--------+-------+\n",
      "| mAP     |     |      |        | 0.151 |\n",
      "+---------+-----+------+--------+-------+\n",
      "2022-06-20 20:47:36,607 - mmdet - INFO - Epoch(val) [1][13]\tAP50: 0.1510, mAP: 0.1510\n",
      "2022-06-20 20:47:36,607 - mmdet - INFO - Epoch(val) [1][13]\tAP50: 0.1510, mAP: 0.1510\n",
      "2022-06-20 20:48:05,158 - mmdet - INFO - Epoch [2][10/15]\tlr: 2.000e-03, eta: 0:05:00, time: 2.839, data_time: 2.249, memory: 3370, loss_cls: 0.8379, loss_bbox: 0.5342, loss_bbox_rf: 0.7022, loss: 2.0742\n",
      "2022-06-20 20:48:05,158 - mmdet - INFO - Epoch [2][10/15]\tlr: 2.000e-03, eta: 0:05:00, time: 2.839, data_time: 2.249, memory: 3370, loss_cls: 0.8379, loss_bbox: 0.5342, loss_bbox_rf: 0.7022, loss: 2.0742\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 13/13, 0.8 task/s, elapsed: 16s, ETA:     0s\n",
      "---------------iou_thr: 0.5---------------\n",
      "2022-06-20 20:48:34,646 - mmdet - INFO - \n",
      "+---------+-----+------+--------+-------+\n",
      "| class   | gts | dets | recall | ap    |\n",
      "+---------+-----+------+--------+-------+\n",
      "| section | 500 | 1300 | 0.546  | 0.265 |\n",
      "+---------+-----+------+--------+-------+\n",
      "| mAP     |     |      |        | 0.265 |\n",
      "+---------+-----+------+--------+-------+\n",
      "2022-06-20 20:48:34,646 - mmdet - INFO - \n",
      "+---------+-----+------+--------+-------+\n",
      "| class   | gts | dets | recall | ap    |\n",
      "+---------+-----+------+--------+-------+\n",
      "| section | 500 | 1300 | 0.546  | 0.265 |\n",
      "+---------+-----+------+--------+-------+\n",
      "| mAP     |     |      |        | 0.265 |\n",
      "+---------+-----+------+--------+-------+\n",
      "2022-06-20 20:48:34,651 - mmdet - INFO - Epoch(val) [2][13]\tAP50: 0.2650, mAP: 0.2654\n",
      "2022-06-20 20:48:34,651 - mmdet - INFO - Epoch(val) [2][13]\tAP50: 0.2650, mAP: 0.2654\n",
      "2022-06-20 20:49:03,489 - mmdet - INFO - Epoch [3][10/15]\tlr: 2.000e-03, eta: 0:04:04, time: 2.872, data_time: 2.251, memory: 3370, loss_cls: 0.8185, loss_bbox: 0.5014, loss_bbox_rf: 0.6618, loss: 1.9817\n",
      "2022-06-20 20:49:03,489 - mmdet - INFO - Epoch [3][10/15]\tlr: 2.000e-03, eta: 0:04:04, time: 2.872, data_time: 2.251, memory: 3370, loss_cls: 0.8185, loss_bbox: 0.5014, loss_bbox_rf: 0.6618, loss: 1.9817\n",
      "2022-06-20 20:49:16,781 - mmdet - INFO - Saving checkpoint at 3 epochs\n",
      "2022-06-20 20:49:16,781 - mmdet - INFO - Saving checkpoint at 3 epochs\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 13/13, 0.8 task/s, elapsed: 16s, ETA:     0s\n",
      "---------------iou_thr: 0.5---------------\n",
      "2022-06-20 20:49:35,867 - mmdet - INFO - \n",
      "+---------+-----+------+--------+-------+\n",
      "| class   | gts | dets | recall | ap    |\n",
      "+---------+-----+------+--------+-------+\n",
      "| section | 500 | 1300 | 0.588  | 0.271 |\n",
      "+---------+-----+------+--------+-------+\n",
      "| mAP     |     |      |        | 0.271 |\n",
      "+---------+-----+------+--------+-------+\n",
      "2022-06-20 20:49:35,867 - mmdet - INFO - \n",
      "+---------+-----+------+--------+-------+\n",
      "| class   | gts | dets | recall | ap    |\n",
      "+---------+-----+------+--------+-------+\n",
      "| section | 500 | 1300 | 0.588  | 0.271 |\n",
      "+---------+-----+------+--------+-------+\n",
      "| mAP     |     |      |        | 0.271 |\n",
      "+---------+-----+------+--------+-------+\n",
      "2022-06-20 20:49:35,872 - mmdet - INFO - Epoch(val) [3][13]\tAP50: 0.2710, mAP: 0.2713\n",
      "2022-06-20 20:49:35,872 - mmdet - INFO - Epoch(val) [3][13]\tAP50: 0.2710, mAP: 0.2713\n",
      "2022-06-20 20:50:05,597 - mmdet - INFO - Epoch [4][10/15]\tlr: 2.000e-03, eta: 0:03:24, time: 2.960, data_time: 2.328, memory: 3370, loss_cls: 0.6882, loss_bbox: 0.4988, loss_bbox_rf: 0.6527, loss: 1.8398\n",
      "2022-06-20 20:50:05,597 - mmdet - INFO - Epoch [4][10/15]\tlr: 2.000e-03, eta: 0:03:24, time: 2.960, data_time: 2.328, memory: 3370, loss_cls: 0.6882, loss_bbox: 0.4988, loss_bbox_rf: 0.6527, loss: 1.8398\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 13/13, 0.8 task/s, elapsed: 16s, ETA:     0s\n",
      "---------------iou_thr: 0.5---------------\n",
      "2022-06-20 20:50:34,337 - mmdet - INFO - \n",
      "+---------+-----+------+--------+-------+\n",
      "| class   | gts | dets | recall | ap    |\n",
      "+---------+-----+------+--------+-------+\n",
      "| section | 500 | 1300 | 0.656  | 0.379 |\n",
      "+---------+-----+------+--------+-------+\n",
      "| mAP     |     |      |        | 0.379 |\n",
      "+---------+-----+------+--------+-------+\n",
      "2022-06-20 20:50:34,337 - mmdet - INFO - \n",
      "+---------+-----+------+--------+-------+\n",
      "| class   | gts | dets | recall | ap    |\n",
      "+---------+-----+------+--------+-------+\n",
      "| section | 500 | 1300 | 0.656  | 0.379 |\n",
      "+---------+-----+------+--------+-------+\n",
      "| mAP     |     |      |        | 0.379 |\n",
      "+---------+-----+------+--------+-------+\n",
      "2022-06-20 20:50:34,341 - mmdet - INFO - Epoch(val) [4][13]\tAP50: 0.3790, mAP: 0.3786\n",
      "2022-06-20 20:50:34,341 - mmdet - INFO - Epoch(val) [4][13]\tAP50: 0.3790, mAP: 0.3786\n",
      "2022-06-20 20:51:02,836 - mmdet - INFO - Epoch [5][10/15]\tlr: 2.000e-03, eta: 0:02:47, time: 2.836, data_time: 2.212, memory: 3370, loss_cls: 0.6566, loss_bbox: 0.4731, loss_bbox_rf: 0.6189, loss: 1.7486\n",
      "2022-06-20 20:51:02,836 - mmdet - INFO - Epoch [5][10/15]\tlr: 2.000e-03, eta: 0:02:47, time: 2.836, data_time: 2.212, memory: 3370, loss_cls: 0.6566, loss_bbox: 0.4731, loss_bbox_rf: 0.6189, loss: 1.7486\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 13/13, 0.8 task/s, elapsed: 16s, ETA:     0s\n",
      "---------------iou_thr: 0.5---------------\n",
      "2022-06-20 20:51:32,478 - mmdet - INFO - \n",
      "+---------+-----+------+--------+-------+\n",
      "| class   | gts | dets | recall | ap    |\n",
      "+---------+-----+------+--------+-------+\n",
      "| section | 500 | 1300 | 0.694  | 0.415 |\n",
      "+---------+-----+------+--------+-------+\n",
      "| mAP     |     |      |        | 0.415 |\n",
      "+---------+-----+------+--------+-------+\n",
      "2022-06-20 20:51:32,478 - mmdet - INFO - \n",
      "+---------+-----+------+--------+-------+\n",
      "| class   | gts | dets | recall | ap    |\n",
      "+---------+-----+------+--------+-------+\n",
      "| section | 500 | 1300 | 0.694  | 0.415 |\n",
      "+---------+-----+------+--------+-------+\n",
      "| mAP     |     |      |        | 0.415 |\n",
      "+---------+-----+------+--------+-------+\n",
      "2022-06-20 20:51:32,482 - mmdet - INFO - Epoch(val) [5][13]\tAP50: 0.4150, mAP: 0.4153\n",
      "2022-06-20 20:51:32,482 - mmdet - INFO - Epoch(val) [5][13]\tAP50: 0.4150, mAP: 0.4153\n",
      "2022-06-20 20:52:01,027 - mmdet - INFO - Epoch [6][10/15]\tlr: 2.000e-03, eta: 0:02:13, time: 2.841, data_time: 2.201, memory: 3370, loss_cls: 0.6906, loss_bbox: 0.4929, loss_bbox_rf: 0.6487, loss: 1.8322\n",
      "2022-06-20 20:52:01,027 - mmdet - INFO - Epoch [6][10/15]\tlr: 2.000e-03, eta: 0:02:13, time: 2.841, data_time: 2.201, memory: 3370, loss_cls: 0.6906, loss_bbox: 0.4929, loss_bbox_rf: 0.6487, loss: 1.8322\n",
      "2022-06-20 20:52:15,142 - mmdet - INFO - Saving checkpoint at 6 epochs\n",
      "2022-06-20 20:52:15,142 - mmdet - INFO - Saving checkpoint at 6 epochs\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 13/13, 0.8 task/s, elapsed: 16s, ETA:     0s\n",
      "---------------iou_thr: 0.5---------------\n",
      "2022-06-20 20:52:34,288 - mmdet - INFO - \n",
      "+---------+-----+------+--------+-------+\n",
      "| class   | gts | dets | recall | ap    |\n",
      "+---------+-----+------+--------+-------+\n",
      "| section | 500 | 1300 | 0.708  | 0.437 |\n",
      "+---------+-----+------+--------+-------+\n",
      "| mAP     |     |      |        | 0.437 |\n",
      "+---------+-----+------+--------+-------+\n",
      "2022-06-20 20:52:34,288 - mmdet - INFO - \n",
      "+---------+-----+------+--------+-------+\n",
      "| class   | gts | dets | recall | ap    |\n",
      "+---------+-----+------+--------+-------+\n",
      "| section | 500 | 1300 | 0.708  | 0.437 |\n",
      "+---------+-----+------+--------+-------+\n",
      "| mAP     |     |      |        | 0.437 |\n",
      "+---------+-----+------+--------+-------+\n",
      "2022-06-20 20:52:34,292 - mmdet - INFO - Epoch(val) [6][13]\tAP50: 0.4370, mAP: 0.4365\n",
      "2022-06-20 20:52:34,292 - mmdet - INFO - Epoch(val) [6][13]\tAP50: 0.4370, mAP: 0.4365\n",
      "2022-06-20 20:53:02,733 - mmdet - INFO - Epoch [7][10/15]\tlr: 2.000e-03, eta: 0:01:41, time: 2.828, data_time: 2.217, memory: 3370, loss_cls: 0.7472, loss_bbox: 0.4475, loss_bbox_rf: 0.5892, loss: 1.7839\n",
      "2022-06-20 20:53:02,733 - mmdet - INFO - Epoch [7][10/15]\tlr: 2.000e-03, eta: 0:01:41, time: 2.828, data_time: 2.217, memory: 3370, loss_cls: 0.7472, loss_bbox: 0.4475, loss_bbox_rf: 0.5892, loss: 1.7839\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 13/13, 0.8 task/s, elapsed: 16s, ETA:     0s\n",
      "---------------iou_thr: 0.5---------------\n",
      "2022-06-20 20:53:32,581 - mmdet - INFO - \n",
      "+---------+-----+------+--------+-------+\n",
      "| class   | gts | dets | recall | ap    |\n",
      "+---------+-----+------+--------+-------+\n",
      "| section | 500 | 1300 | 0.706  | 0.448 |\n",
      "+---------+-----+------+--------+-------+\n",
      "| mAP     |     |      |        | 0.448 |\n",
      "+---------+-----+------+--------+-------+\n",
      "2022-06-20 20:53:32,581 - mmdet - INFO - \n",
      "+---------+-----+------+--------+-------+\n",
      "| class   | gts | dets | recall | ap    |\n",
      "+---------+-----+------+--------+-------+\n",
      "| section | 500 | 1300 | 0.706  | 0.448 |\n",
      "+---------+-----+------+--------+-------+\n",
      "| mAP     |     |      |        | 0.448 |\n",
      "+---------+-----+------+--------+-------+\n",
      "2022-06-20 20:53:32,586 - mmdet - INFO - Epoch(val) [7][13]\tAP50: 0.4480, mAP: 0.4484\n",
      "2022-06-20 20:53:32,586 - mmdet - INFO - Epoch(val) [7][13]\tAP50: 0.4480, mAP: 0.4484\n",
      "2022-06-20 20:54:01,749 - mmdet - INFO - Epoch [8][10/15]\tlr: 2.000e-03, eta: 0:01:10, time: 2.907, data_time: 2.275, memory: 3370, loss_cls: 0.6880, loss_bbox: 0.4414, loss_bbox_rf: 0.5813, loss: 1.7106\n",
      "2022-06-20 20:54:01,749 - mmdet - INFO - Epoch [8][10/15]\tlr: 2.000e-03, eta: 0:01:10, time: 2.907, data_time: 2.275, memory: 3370, loss_cls: 0.6880, loss_bbox: 0.4414, loss_bbox_rf: 0.5813, loss: 1.7106\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 13/13, 0.8 task/s, elapsed: 16s, ETA:     0s\n",
      "---------------iou_thr: 0.5---------------\n",
      "2022-06-20 20:54:30,978 - mmdet - INFO - \n",
      "+---------+-----+------+--------+-------+\n",
      "| class   | gts | dets | recall | ap    |\n",
      "+---------+-----+------+--------+-------+\n",
      "| section | 500 | 1300 | 0.710  | 0.451 |\n",
      "+---------+-----+------+--------+-------+\n",
      "| mAP     |     |      |        | 0.451 |\n",
      "+---------+-----+------+--------+-------+\n",
      "2022-06-20 20:54:30,978 - mmdet - INFO - \n",
      "+---------+-----+------+--------+-------+\n",
      "| class   | gts | dets | recall | ap    |\n",
      "+---------+-----+------+--------+-------+\n",
      "| section | 500 | 1300 | 0.710  | 0.451 |\n",
      "+---------+-----+------+--------+-------+\n",
      "| mAP     |     |      |        | 0.451 |\n",
      "+---------+-----+------+--------+-------+\n",
      "2022-06-20 20:54:30,983 - mmdet - INFO - Epoch(val) [8][13]\tAP50: 0.4510, mAP: 0.4514\n",
      "2022-06-20 20:54:30,983 - mmdet - INFO - Epoch(val) [8][13]\tAP50: 0.4510, mAP: 0.4514\n",
      "2022-06-20 20:54:59,595 - mmdet - INFO - Epoch [9][10/15]\tlr: 2.000e-04, eta: 0:00:40, time: 2.848, data_time: 2.227, memory: 3370, loss_cls: 0.6473, loss_bbox: 0.5104, loss_bbox_rf: 0.6762, loss: 1.8340\n",
      "2022-06-20 20:54:59,595 - mmdet - INFO - Epoch [9][10/15]\tlr: 2.000e-04, eta: 0:00:40, time: 2.848, data_time: 2.227, memory: 3370, loss_cls: 0.6473, loss_bbox: 0.5104, loss_bbox_rf: 0.6762, loss: 1.8340\n",
      "2022-06-20 20:55:13,501 - mmdet - INFO - Saving checkpoint at 9 epochs\n",
      "2022-06-20 20:55:13,501 - mmdet - INFO - Saving checkpoint at 9 epochs\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 13/13, 0.8 task/s, elapsed: 16s, ETA:     0s\n",
      "---------------iou_thr: 0.5---------------\n",
      "2022-06-20 20:55:32,467 - mmdet - INFO - \n",
      "+---------+-----+------+--------+-------+\n",
      "| class   | gts | dets | recall | ap    |\n",
      "+---------+-----+------+--------+-------+\n",
      "| section | 500 | 1300 | 0.710  | 0.455 |\n",
      "+---------+-----+------+--------+-------+\n",
      "| mAP     |     |      |        | 0.455 |\n",
      "+---------+-----+------+--------+-------+\n",
      "2022-06-20 20:55:32,467 - mmdet - INFO - \n",
      "+---------+-----+------+--------+-------+\n",
      "| class   | gts | dets | recall | ap    |\n",
      "+---------+-----+------+--------+-------+\n",
      "| section | 500 | 1300 | 0.710  | 0.455 |\n",
      "+---------+-----+------+--------+-------+\n",
      "| mAP     |     |      |        | 0.455 |\n",
      "+---------+-----+------+--------+-------+\n",
      "2022-06-20 20:55:32,471 - mmdet - INFO - Epoch(val) [9][13]\tAP50: 0.4550, mAP: 0.4546\n",
      "2022-06-20 20:55:32,471 - mmdet - INFO - Epoch(val) [9][13]\tAP50: 0.4550, mAP: 0.4546\n",
      "2022-06-20 20:56:01,787 - mmdet - INFO - Epoch [10][10/15]\tlr: 2.000e-04, eta: 0:00:10, time: 2.918, data_time: 2.317, memory: 3370, loss_cls: 0.6683, loss_bbox: 0.4151, loss_bbox_rf: 0.5469, loss: 1.6303\n",
      "2022-06-20 20:56:01,787 - mmdet - INFO - Epoch [10][10/15]\tlr: 2.000e-04, eta: 0:00:10, time: 2.918, data_time: 2.317, memory: 3370, loss_cls: 0.6683, loss_bbox: 0.4151, loss_bbox_rf: 0.5469, loss: 1.6303\n",
      "2022-06-20 20:56:14,821 - mmdet - INFO - Saving checkpoint at 10 epochs\n",
      "2022-06-20 20:56:14,821 - mmdet - INFO - Saving checkpoint at 10 epochs\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 13/13, 0.8 task/s, elapsed: 16s, ETA:     0s\n",
      "---------------iou_thr: 0.5---------------\n",
      "2022-06-20 20:56:33,865 - mmdet - INFO - \n",
      "+---------+-----+------+--------+-------+\n",
      "| class   | gts | dets | recall | ap    |\n",
      "+---------+-----+------+--------+-------+\n",
      "| section | 500 | 1300 | 0.712  | 0.456 |\n",
      "+---------+-----+------+--------+-------+\n",
      "| mAP     |     |      |        | 0.456 |\n",
      "+---------+-----+------+--------+-------+\n",
      "2022-06-20 20:56:33,865 - mmdet - INFO - \n",
      "+---------+-----+------+--------+-------+\n",
      "| class   | gts | dets | recall | ap    |\n",
      "+---------+-----+------+--------+-------+\n",
      "| section | 500 | 1300 | 0.712  | 0.456 |\n",
      "+---------+-----+------+--------+-------+\n",
      "| mAP     |     |      |        | 0.456 |\n",
      "+---------+-----+------+--------+-------+\n",
      "2022-06-20 20:56:33,869 - mmdet - INFO - Epoch(val) [10][13]\tAP50: 0.4560, mAP: 0.4558\n",
      "2022-06-20 20:56:33,869 - mmdet - INFO - Epoch(val) [10][13]\tAP50: 0.4560, mAP: 0.4558\n"
     ]
    }
   ],
   "source": [
    "train_detector(model, datasets, cfg, validate=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The log starts with a warning about a size mismatch that we can ignore. It is due to the fact that the weights we load belong to a model that was trained on the COCO dataset which has 80 different classes whereas we only have one class to detect.\n",
    "\n",
    "Since the *mAP* keep increasing it would make sense to continue training the model for longer. \n",
    "But before we do that let's make sure that the rest of the process works.\n",
    "\n",
    "**Note**: \n",
    "- **If you get an error, try rerunning the notebook starting with the loading of the config.** \n",
    "- **If you get the error *RuntimeError: Expected 4-dimensional input for 4-dimensional weight [64, 3, 7, 7], but got 5-dimensional input of size [1, 3, 3, 928, 768] instead* change the instance to one with a GPU.** \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running the Model\n",
    "\n",
    "After training the model we can now apply it on a new image and look at the predictions. \n",
    "For this, we first load the image and initalize the model from a stored checkpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_image = '1_D.jpg'\n",
    "img =  mmcv.imread(f'{data_folder}/jpgs/{example_image}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load checkpoint from local path: /root/data/gdsc5-tutorials-public/data/vfnet_r50_exp5/epoch_10.pth\n"
     ]
    }
   ],
   "source": [
    "# checkpoint = f'{cfg.work_dir}epoch_3.pth' # Select one of the model checkpoints to load in\n",
    "# checkpoint = f'{cfg.work_dir}epoch_12.pth' # \n",
    "# checkpoint = f'{cfg.work_dir}epoch_36.pth' #\n",
    "# checkpoint = f'{cfg.work_dir}epoch_8.pth' # submission 5\n",
    "checkpoint = f'{cfg.work_dir}epoch_10.pth' # submission 6\n",
    "\n",
    "model = init_detector(cfg, checkpoint, device='cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[4.3058022e+03, 3.7138210e+03, 5.1693896e+03, 4.5976689e+03,\n",
       "        7.5891238e-01],\n",
       "       [2.8863604e+03, 8.3972986e+02, 3.5336499e+03, 1.5224211e+03,\n",
       "        7.5781757e-01]], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detections = inference_detector(model, img)\n",
    "print(len(detections))  \n",
    "detections[0][:2]  # Show the first two entries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*detections* is a list of all the detected worm sections. Every detection is a 5-tuple of the form *(xmin, ymin, xmax, ymax, score)*, i.e. the location of the bounding box followed by the confidence.\n",
    "\n",
    "**Exercise:**\n",
    "- Plot the predicted worm boxes. You may use the code provided in tutorial 2.\n",
    "- Load the model weights of a different checkpoint, e.g. after the first epoch. What are the differences?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating the model\n",
    "\n",
    "To get an idea how well we're doing we can run the same evaluation function that will be used for the leaderboard on our example file.\n",
    "For this we first need to convert to model output into the format that is readable by our scoring function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>xmin</th>\n",
       "      <th>ymin</th>\n",
       "      <th>xmax</th>\n",
       "      <th>ymax</th>\n",
       "      <th>detection_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>section_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1_D.jpg@4305-5169-3713-4597</th>\n",
       "      <td>1_D.jpg</td>\n",
       "      <td>4305</td>\n",
       "      <td>3713</td>\n",
       "      <td>5169</td>\n",
       "      <td>4597</td>\n",
       "      <td>0.758912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1_D.jpg@2886-3533-839-1522</th>\n",
       "      <td>1_D.jpg</td>\n",
       "      <td>2886</td>\n",
       "      <td>839</td>\n",
       "      <td>3533</td>\n",
       "      <td>1522</td>\n",
       "      <td>0.757818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1_D.jpg@5347-5873-2714-3309</th>\n",
       "      <td>1_D.jpg</td>\n",
       "      <td>5347</td>\n",
       "      <td>2714</td>\n",
       "      <td>5873</td>\n",
       "      <td>3309</td>\n",
       "      <td>0.754759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1_D.jpg@3870-4640-2477-3671</th>\n",
       "      <td>1_D.jpg</td>\n",
       "      <td>3870</td>\n",
       "      <td>2477</td>\n",
       "      <td>4640</td>\n",
       "      <td>3671</td>\n",
       "      <td>0.739739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1_D.jpg@4612-5161-3199-3624</th>\n",
       "      <td>1_D.jpg</td>\n",
       "      <td>4612</td>\n",
       "      <td>3199</td>\n",
       "      <td>5161</td>\n",
       "      <td>3624</td>\n",
       "      <td>0.735658</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            file_name  xmin  ymin  xmax  ymax  detection_score\n",
       "section_id                                                                    \n",
       "1_D.jpg@4305-5169-3713-4597   1_D.jpg  4305  3713  5169  4597         0.758912\n",
       "1_D.jpg@2886-3533-839-1522    1_D.jpg  2886   839  3533  1522         0.757818\n",
       "1_D.jpg@5347-5873-2714-3309   1_D.jpg  5347  2714  5873  3309         0.754759\n",
       "1_D.jpg@3870-4640-2477-3671   1_D.jpg  3870  2477  4640  3671         0.739739\n",
       "1_D.jpg@4612-5161-3199-3624   1_D.jpg  4612  3199  5161  3624         0.735658"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = ['section_id', 'file_name', 'xmin', 'xmax', 'ymin', 'ymax', 'detection_score']\n",
    "df_results = pd.DataFrame(columns=columns)\n",
    "\n",
    "predictions = []\n",
    "\n",
    "# Loop over all detected boxes and convert the information into a dictionary\n",
    "for box in detections[0]:\n",
    "    xmin, ymin, xmax, ymax, score = box\n",
    "    xmin, ymin, xmax, ymax = int(xmin), int(ymin), int(xmax), int(ymax)  # Convert predicted coordinates to integer values\n",
    "    box_dict = dict(\n",
    "        section_id=f'{example_image}@{xmin}-{xmax}-{ymin}-{ymax}',\n",
    "        file_name=example_image,\n",
    "        xmin=xmin,\n",
    "        ymin=ymin,\n",
    "        xmax=xmax,\n",
    "        ymax=ymax,\n",
    "        detection_score=score\n",
    "    )\n",
    "    predictions.append(box_dict)\n",
    "\n",
    "# Convert the dictionary into a dataframe with section_id as index\n",
    "prediction_df = pd.DataFrame(predictions)\n",
    "prediction_df.set_index('section_id', inplace=True)\n",
    "prediction_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we restrict our dataset to only the file for which we made predictions (*1_D.jpg*) and run the score function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth = section_df.loc[section_df.file_name==example_image]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = PredictionEvaluator(ground_truth)\n",
    "thresholds = [0.5, 0.6, 0.7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the leaderboard, the predicted worm section boxes are compared to the actual worm section boxes. We compute the [Intersection over Union (IOU)](https://towardsdatascience.com/iou-a-better-detection-evaluation-metric-45a511185be1) between the boxes. If the value is greater than a threshold (e.g. 0.5) the prediction counts as a match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-20 21:02:40,355 - gdsc_score - INFO - Computing results for threshold: 0.5\n",
      "2022-06-20 21:02:40,356 - PredictionEvaluator - INFO - Matching sections\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 24.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-20 21:02:40,400 - PredictionEvaluator - INFO - Merging matched sections\n",
      "2022-06-20 21:02:40,410 - PredictionEvaluator - INFO - Done matching sections\n",
      "2022-06-20 21:02:40,410 - PredictionEvaluator - INFO - Evaluating predictions\n",
      "2022-06-20 21:02:40,411 - PredictionEvaluator - INFO - Computing overall scores\n",
      "2022-06-20 21:02:40,413 - gdsc_score - INFO - Computing results for threshold: 0.6\n",
      "2022-06-20 21:02:40,414 - PredictionEvaluator - INFO - Matching sections\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 25.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-20 21:02:40,457 - PredictionEvaluator - INFO - Merging matched sections\n",
      "2022-06-20 21:02:40,465 - PredictionEvaluator - INFO - Done matching sections\n",
      "2022-06-20 21:02:40,466 - PredictionEvaluator - INFO - Evaluating predictions\n",
      "2022-06-20 21:02:40,467 - PredictionEvaluator - INFO - Computing overall scores\n",
      "2022-06-20 21:02:40,469 - gdsc_score - INFO - Computing results for threshold: 0.7\n",
      "2022-06-20 21:02:40,469 - PredictionEvaluator - INFO - Matching sections\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 25.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-20 21:02:40,512 - PredictionEvaluator - INFO - Merging matched sections\n",
      "2022-06-20 21:02:40,521 - PredictionEvaluator - INFO - Done matching sections\n",
      "2022-06-20 21:02:40,521 - PredictionEvaluator - INFO - Evaluating predictions\n",
      "2022-06-20 21:02:40,522 - PredictionEvaluator - INFO - Computing overall scores\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'detection_acc@iou0.5': 35.92,\n",
       " 'detection_tp@iou0.5': 37,\n",
       " 'detection_fp@iou0.5': 63,\n",
       " 'detection_fn@iou0.5': 3,\n",
       " 'detection_acc@iou0.6': 33.33,\n",
       " 'detection_tp@iou0.6': 35,\n",
       " 'detection_fp@iou0.6': 65,\n",
       " 'detection_fn@iou0.6': 5,\n",
       " 'detection_acc@iou0.7': 32.08,\n",
       " 'detection_tp@iou0.7': 34,\n",
       " 'detection_fp@iou0.7': 66,\n",
       " 'detection_fn@iou0.7': 6,\n",
       " 'score': 101.33}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_leaderboard_score(prediction_df, thresholds, evaluator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function *get_leaderboard_score* gives us a lot of information that we can use to debug our model. \n",
    "- *score* is the score that will be shown in the leaderboard. It is the sum of the individual detection_acc@X values.\n",
    "- Additionally, for each IOU threshold the *accuracy, true positives, false positives* and *false negatives* are computed.\n",
    "\n",
    "**Exercise:**\n",
    "- Which type of error is the most common? How could you combat this?\n",
    "- The output shows true positives (tp), false positives (fp), false negatives (fn) but no true negatives. Why is that?\n",
    "- Evaluate the model on the *dummy_test* dataset we created previously."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A first submission\n",
    "\n",
    "Now, we have all the pieces in place to create our first submission. We will predict the worm sections for all files and store them in a DataFrame.\n",
    "We will need to provide a prediction for all the files that are listed in *test_files.csv*. Let's load the file first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['100_D.jpg', '100_C.jpg', '100_B.jpg', '100_AA.jpg', '100_A.jpg',\n",
       "       '101_DD.jpg', '101_C.jpg', '101_B.jpg', '101_AA.jpg', '101_A.jpg',\n",
       "       '86_D.jpg', '86_C.jpg', '86_B.jpg', '86_AA.jpg', '86_A.jpg',\n",
       "       '88_D.jpg', '88_C.jpg', '88_B.jpg', '88_A.jpg', '89_D.jpg',\n",
       "       '89_C.jpg', '89_B.jpg', '89_AA.jpg', '89_A.jpg', '90_D.jpg',\n",
       "       '90_C.jpg', '90_B.jpg', '90_AA.jpg', '90_A.jpg', '91_D.jpg',\n",
       "       '91_C.jpg', '91_B.jpg', '91_AA.jpg', '91_A.jpg', '92_D.jpg',\n",
       "       '92_C.jpg', '92_B.jpg', '92_AA.jpg', '92_A.jpg', '93_D.jpg',\n",
       "       '93_C.jpg', '93_B.jpg', '93_AA.jpg', '93_A.jpg', '94_D.jpg',\n",
       "       '94_C.jpg', '94_B.jpg', '94_AA.jpg', '94_A.jpg', '95_D.jpg',\n",
       "       '95_C.jpg', '95_B.jpg', '95_AA.jpg', '95_A.jpg', '96_D.jpg',\n",
       "       '96_C.jpg', '96_B.jpg', '96_AA.jpg', '96_A.jpg', '97_D.jpg',\n",
       "       '97_C.jpg', '97_B.jpg', '97_A.jpg', '98_D.jpg', '98_C.jpg',\n",
       "       '98_B.jpg', '98_AA.jpg', '98_A.jpg', '99_D.jpg', '99_C.jpg',\n",
       "       '99_B.jpg', '99_AA.jpg', '99_A.jpg'], dtype=object)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = pd.read_csv(f'{data_folder}/test_files.csv', sep=';', header=None)\n",
    "file_names = files[0].values\n",
    "file_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For simplicity, we created a function that runs the above code on all file names and returns a dataframe with the predictions. This will take around five minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load checkpoint from local path: /root/data/gdsc5-tutorials-public/data/vfnet_r50_exp5/epoch_10.pth\n",
      "2022-06-20 21:03:05,185 - detection_util - INFO - Creating predictions for 73 files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/73 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-20 21:03:05,188 - detection_util - INFO - Processing file: 100_D.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 1/73 [00:00<01:08,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-20 21:03:06,141 - detection_util - INFO - Processing file: 100_C.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 2/73 [00:01<01:06,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-20 21:03:07,074 - detection_util - INFO - Processing file: 100_B.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 3/73 [00:02<00:55,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-20 21:03:07,684 - detection_util - INFO - Processing file: 100_AA.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 4/73 [00:03<00:51,  1.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-20 21:03:08,357 - detection_util - INFO - Processing file: 100_A.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 5/73 [00:03<00:52,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-20 21:03:09,182 - detection_util - INFO - Processing file: 101_DD.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 6/73 [00:04<00:50,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-20 21:03:09,906 - detection_util - INFO - Processing file: 101_C.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 7/73 [00:05<00:50,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-20 21:03:10,682 - detection_util - INFO - Processing file: 101_B.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 8/73 [00:06<00:49,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-20 21:03:11,429 - detection_util - INFO - Processing file: 101_AA.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 9/73 [00:06<00:47,  1.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-20 21:03:12,156 - detection_util - INFO - Processing file: 101_A.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▎        | 10/73 [00:07<00:46,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-20 21:03:12,860 - detection_util - INFO - Processing file: 86_D.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 11/73 [00:08<00:49,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-20 21:03:13,786 - detection_util - INFO - Processing file: 86_C.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▋        | 12/73 [00:09<00:54,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-20 21:03:14,913 - detection_util - INFO - Processing file: 86_B.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 13/73 [00:10<00:53,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-20 21:03:15,814 - detection_util - INFO - Processing file: 86_AA.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 14/73 [00:11<00:51,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-20 21:03:16,637 - detection_util - INFO - Processing file: 86_A.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 15/73 [00:12<00:51,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-20 21:03:17,558 - detection_util - INFO - Processing file: 88_D.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 16/73 [00:13<00:57,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-20 21:03:18,859 - detection_util - INFO - Processing file: 88_C.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 17/73 [00:15<01:02,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-20 21:03:20,214 - detection_util - INFO - Processing file: 88_B.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 18/73 [00:16<01:03,  1.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-20 21:03:21,447 - detection_util - INFO - Processing file: 88_A.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 19/73 [00:17<01:03,  1.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-20 21:03:22,676 - detection_util - INFO - Processing file: 89_D.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 20/73 [00:18<00:53,  1.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-20 21:03:23,275 - detection_util - INFO - Processing file: 89_C.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 21/73 [00:18<00:49,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-20 21:03:24,110 - detection_util - INFO - Processing file: 89_B.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 22/73 [00:19<00:43,  1.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-20 21:03:24,707 - detection_util - INFO - Processing file: 89_AA.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 23/73 [00:20<00:42,  1.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-20 21:03:25,557 - detection_util - INFO - Processing file: 89_A.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 24/73 [00:21<00:38,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-20 21:03:26,204 - detection_util - INFO - Processing file: 90_D.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 25/73 [00:21<00:39,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-20 21:03:27,138 - detection_util - INFO - Processing file: 90_C.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 26/73 [00:22<00:42,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-20 21:03:28,183 - detection_util - INFO - Processing file: 90_B.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 27/73 [00:24<00:43,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-20 21:03:29,247 - detection_util - INFO - Processing file: 90_AA.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 28/73 [00:25<00:46,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-20 21:03:30,469 - detection_util - INFO - Processing file: 90_A.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███▉      | 29/73 [00:26<00:46,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-20 21:03:31,587 - detection_util - INFO - Processing file: 91_D.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 30/73 [00:27<00:45,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-20 21:03:32,637 - detection_util - INFO - Processing file: 91_C.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 31/73 [00:28<00:44,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-20 21:03:33,714 - detection_util - INFO - Processing file: 91_B.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 32/73 [00:29<00:44,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-20 21:03:34,869 - detection_util - INFO - Processing file: 91_AA.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 33/73 [00:30<00:43,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-20 21:03:35,948 - detection_util - INFO - Processing file: 91_A.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 34/73 [00:32<00:44,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-20 21:03:37,209 - detection_util - INFO - Processing file: 92_D.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 35/73 [00:33<00:43,  1.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-20 21:03:38,390 - detection_util - INFO - Processing file: 92_C.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 36/73 [00:34<00:44,  1.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-20 21:03:39,681 - detection_util - INFO - Processing file: 92_B.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 37/73 [00:35<00:45,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-20 21:03:41,138 - detection_util - INFO - Processing file: 92_AA.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 38/73 [00:37<00:44,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-20 21:03:42,391 - detection_util - INFO - Processing file: 92_A.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 39/73 [00:38<00:41,  1.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-20 21:03:43,523 - detection_util - INFO - Processing file: 93_D.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 40/73 [00:39<00:42,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-20 21:03:44,987 - detection_util - INFO - Processing file: 93_C.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 41/73 [00:41<00:42,  1.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-20 21:03:46,371 - detection_util - INFO - Processing file: 93_B.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 42/73 [00:42<00:41,  1.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-20 21:03:47,699 - detection_util - INFO - Processing file: 93_AA.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 43/73 [00:43<00:37,  1.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-20 21:03:48,782 - detection_util - INFO - Processing file: 93_A.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 44/73 [00:44<00:36,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-20 21:03:50,090 - detection_util - INFO - Processing file: 94_D.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 45/73 [00:46<00:37,  1.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-20 21:03:51,597 - detection_util - INFO - Processing file: 94_C.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 46/73 [00:47<00:36,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-20 21:03:52,964 - detection_util - INFO - Processing file: 94_B.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 47/73 [00:49<00:35,  1.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-20 21:03:54,408 - detection_util - INFO - Processing file: 94_AA.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 48/73 [00:50<00:32,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-20 21:03:55,537 - detection_util - INFO - Processing file: 94_A.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 49/73 [00:51<00:31,  1.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-20 21:03:56,892 - detection_util - INFO - Processing file: 95_D.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 50/73 [00:52<00:27,  1.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-20 21:03:57,847 - detection_util - INFO - Processing file: 95_C.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████▉   | 51/73 [00:53<00:25,  1.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-20 21:03:58,963 - detection_util - INFO - Processing file: 95_B.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 52/73 [00:54<00:23,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-20 21:03:59,951 - detection_util - INFO - Processing file: 95_AA.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 53/73 [00:55<00:21,  1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-20 21:04:00,917 - detection_util - INFO - Processing file: 95_A.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 54/73 [00:56<00:20,  1.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-20 21:04:01,960 - detection_util - INFO - Processing file: 96_D.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 55/73 [00:57<00:19,  1.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-20 21:04:03,028 - detection_util - INFO - Processing file: 96_C.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 56/73 [00:58<00:16,  1.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-20 21:04:03,857 - detection_util - INFO - Processing file: 96_B.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 57/73 [00:59<00:16,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-20 21:04:05,001 - detection_util - INFO - Processing file: 96_AA.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 58/73 [01:00<00:15,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-20 21:04:06,020 - detection_util - INFO - Processing file: 96_A.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 59/73 [01:02<00:15,  1.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-20 21:04:07,275 - detection_util - INFO - Processing file: 97_D.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 60/73 [01:03<00:14,  1.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-20 21:04:08,552 - detection_util - INFO - Processing file: 97_C.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▎ | 61/73 [01:04<00:13,  1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-20 21:04:09,474 - detection_util - INFO - Processing file: 97_B.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▍ | 62/73 [01:05<00:11,  1.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-20 21:04:10,508 - detection_util - INFO - Processing file: 97_A.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▋ | 63/73 [01:06<00:10,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-20 21:04:11,496 - detection_util - INFO - Processing file: 98_D.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 64/73 [01:07<00:09,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-20 21:04:12,449 - detection_util - INFO - Processing file: 98_C.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 65/73 [01:08<00:07,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-20 21:04:13,329 - detection_util - INFO - Processing file: 98_B.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 66/73 [01:09<00:07,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-20 21:04:14,444 - detection_util - INFO - Processing file: 98_AA.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 67/73 [01:10<00:05,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-20 21:04:15,366 - detection_util - INFO - Processing file: 98_A.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 68/73 [01:11<00:04,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-20 21:04:16,274 - detection_util - INFO - Processing file: 99_D.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▍| 69/73 [01:12<00:03,  1.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-20 21:04:17,342 - detection_util - INFO - Processing file: 99_C.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 70/73 [01:12<00:02,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-20 21:04:18,139 - detection_util - INFO - Processing file: 99_B.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 71/73 [01:13<00:01,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-20 21:04:19,051 - detection_util - INFO - Processing file: 99_AA.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▊| 72/73 [01:14<00:00,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-20 21:04:19,775 - detection_util - INFO - Processing file: 99_A.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 73/73 [01:15<00:00,  1.04s/it]\n"
     ]
    }
   ],
   "source": [
    "prediction_df = create_predictions(file_names, cfg, checkpoint, device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>xmin</th>\n",
       "      <th>ymin</th>\n",
       "      <th>xmax</th>\n",
       "      <th>ymax</th>\n",
       "      <th>detection_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>section_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100_D.jpg@1035-1212-1140-1428</th>\n",
       "      <td>100_D.jpg</td>\n",
       "      <td>1035</td>\n",
       "      <td>1140</td>\n",
       "      <td>1212</td>\n",
       "      <td>1428</td>\n",
       "      <td>0.645738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100_D.jpg@382-692-1289-1691</th>\n",
       "      <td>100_D.jpg</td>\n",
       "      <td>382</td>\n",
       "      <td>1289</td>\n",
       "      <td>692</td>\n",
       "      <td>1691</td>\n",
       "      <td>0.641257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100_D.jpg@1258-1469-1187-1400</th>\n",
       "      <td>100_D.jpg</td>\n",
       "      <td>1258</td>\n",
       "      <td>1187</td>\n",
       "      <td>1469</td>\n",
       "      <td>1400</td>\n",
       "      <td>0.629040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100_D.jpg@1727-1962-4362-4603</th>\n",
       "      <td>100_D.jpg</td>\n",
       "      <td>1727</td>\n",
       "      <td>4362</td>\n",
       "      <td>1962</td>\n",
       "      <td>4603</td>\n",
       "      <td>0.624631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100_D.jpg@1881-2061-2587-2841</th>\n",
       "      <td>100_D.jpg</td>\n",
       "      <td>1881</td>\n",
       "      <td>2587</td>\n",
       "      <td>2061</td>\n",
       "      <td>2841</td>\n",
       "      <td>0.609023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               file_name  xmin  ymin  xmax  ymax  \\\n",
       "section_id                                                         \n",
       "100_D.jpg@1035-1212-1140-1428  100_D.jpg  1035  1140  1212  1428   \n",
       "100_D.jpg@382-692-1289-1691    100_D.jpg   382  1289   692  1691   \n",
       "100_D.jpg@1258-1469-1187-1400  100_D.jpg  1258  1187  1469  1400   \n",
       "100_D.jpg@1727-1962-4362-4603  100_D.jpg  1727  4362  1962  4603   \n",
       "100_D.jpg@1881-2061-2587-2841  100_D.jpg  1881  2587  2061  2841   \n",
       "\n",
       "                               detection_score  \n",
       "section_id                                      \n",
       "100_D.jpg@1035-1212-1140-1428         0.645738  \n",
       "100_D.jpg@382-692-1289-1691           0.641257  \n",
       "100_D.jpg@1258-1469-1187-1400         0.629040  \n",
       "100_D.jpg@1727-1962-4362-4603         0.624631  \n",
       "100_D.jpg@1881-2061-2587-2841         0.609023  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks good! All that's left is to save the results to a csv and upload it on the [GDSC website](https://gdsc.ce.capgemini.com/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction_df.to_csv(f'{data_folder}/results_tutorial3.csv', sep=';')\n",
    "# prediction_df.to_csv(f'{data_folder}/themav_sub1.csv', sep=';') # submission 1 \n",
    "# prediction_df.to_csv(f'{data_folder}/vfnet_r50_sub2.csv', sep=';') # submission 2 \n",
    "# prediction_df.to_csv(f'{data_folder}/vfnet_r50_sub3.csv', sep=';') # submission 3 wrong submission lr rate not adjusted \n",
    "# prediction_df.to_csv(f'{data_folder}/vfnet_r50_sub4.csv', sep=';') # submission 4 \n",
    "# prediction_df.to_csv(f'{data_folder}/vfnet_r50_sub5.csv', sep=';') # submission 5 \n",
    "prediction_df.to_csv(f'{data_folder}/vfnet_r50_sub6.csv', sep=';') # submission 6 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This submission should lead to a score of around 28. \n",
    "\n",
    "**Exercise:**\n",
    "- The submission score is a lot less than the score of 70.07 we computed above. What are potential reasons for this?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "This notebook covered a LOT of different topics. We covered how to \n",
    "- Train a basic object detection model\n",
    "- Use a trained model to create predictions on a nodule image\n",
    "- How to evaluate the predictions\n",
    "- How to create a first submission\n",
    "\n",
    "all done on a dummy dataset. With this, we have the technical foundations to creating a good submission!\n",
    "\n",
    "In the next tutorial, you will learn how to run and evaluate the model from this notebook on the complete dataset as a Sagemaker training job.\n",
    "\n",
    "**REMINDER: Remember to shut down the *ml.g4dn.xlarge* instance when you aren't using it.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/gdsc5-tutorials-public/notebooks\n",
      "/root/gdsc5-tutorials-public/yolov5_river\n"
     ]
    }
   ],
   "source": [
    "! pwd\n",
    "%cd ../yolov5_river"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data  first_yolo_pred.csv  yolov5\n"
     ]
    }
   ],
   "source": [
    "! ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"first_yolo_pred.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/gdsc5-tutorials-public/data\n"
     ]
    }
   ],
   "source": [
    "%cd ../data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoints\tdummy_train.csv  jpgs\t\t themav_sub1.csv  txts\n",
      "dummy_test.csv\tgdsc_train.csv\t test_files.csv  tutorial_exps\n"
     ]
    }
   ],
   "source": [
    "! ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv(\"themav_sub1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6773, 1), (3375, 1))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.shape , df.shape"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (gdsc5-smstudio-custom/1)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:244473724355:image-version/gdsc5-smstudio-custom/1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
